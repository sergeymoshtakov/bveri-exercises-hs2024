{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "try:\n",
    "    import jupyter_black\n",
    "\n",
    "    jupyter_black.load()\n",
    "except:\n",
    "    print(\"black not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Image Classification\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "- Learn how to model an image classification task\n",
    "- Learn how to systematically implement data prep, model architecture, training-loop, and evaluation\n",
    "- Learn how to incroporate pre-trained models\n",
    "- Learn how to incorporate boilerplate code from [torchvision](https://pytorch.org/vision/0.9/index.html) and  [PyTorch Lightning](https://lightning.ai/docs/pytorch/stable/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a9856bbf98ea570f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Let's define paths, install & load the necessary Python packages.\n",
    "\n",
    "**Optional: Save the notebook to your personal google drive to persist changes.**\n",
    "\n",
    "**Optional: Change runtime to a GPU instance (if using Google Colab)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount your google drive to store data and results (if running the code in Google Colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"In colab: {IN_COLAB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify the following paths if necessary.**\n",
    "\n",
    "That is where your data will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if IN_COLAB:\n",
    "    DATA_PATH = Path(\"/content/drive/MyDrive/bveri\")\n",
    "else:\n",
    "    DATA_PATH = Path(\"/workspace/code/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the package `dl_cv_lectures`.\n",
    "\n",
    "The following code installs the package from a local repository (if available), otherwise it installs it from the exercise repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import dl_cv_lectures\n",
    "\n",
    "    print(\"dl_cv_lectures installed, all good\")\n",
    "except ImportError as e:\n",
    "    import os\n",
    "\n",
    "    if Path(\"/workspace/code/src\").exists():\n",
    "        print(\"Installing from local repo\")\n",
    "        os.system(\"cd /workspace/code  && pip install .\")\n",
    "    else:\n",
    "        print(\"Installing from git repo\")\n",
    "        os.system(\"pip install git+https://github.com/i4Ds/bveri-exercises-hs2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "from typing import Callable\n",
    "\n",
    "import lightning as L\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "import torchshow as ts\n",
    "import torchvision\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.v2 import functional as TF\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import dl_cv_lectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a default device for your computations.\n",
    "\n",
    "**GPU is strongly recommended!** (otherwise the images have to be restricted in size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "projects",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1) Project Selection\n",
    "\n",
    "Choose one of the following projects to work on. \n",
    "\n",
    "All datasets are structured similarily in class-specific image folders.\n",
    "\n",
    "This notebook was thoroughly tested with the cats vs dogs dataset and uses this one as an example. \n",
    "\n",
    "**Choose Cats vs Dogs if you want to mainly click through the notebook.**\n",
    "\n",
    "All other datasets require some (minor!) adaptations. Feel free to choose whichever interests you most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cats vs Dogs\n",
    "\n",
    "**Goal**: Develop a model to classify images of cats and dogs. The dataset is designed to facilitate the identification of these animals from images.\n",
    "\n",
    "**Approach**: Create a Convolutional Neural Network (CNN) to classify the images into two categories: cats and dogs. Experiment with various CNN architectures and techniques to determine the most effective method. Use data augmentation techniques to handle variations in pose, lighting, and background. Ensure the model generalizes well by using cross-validation and monitoring for overfitting.\n",
    "\n",
    "**Dataset**: The dataset contains 25,000 images, with approximately 12,500 images per class (cats and dogs). Each image varies in size and resolution. The data is provided by Microsoft as part of their Kaggle competition.\n",
    "\n",
    "[Source](https://www.microsoft.com/en-us/download/details.aspx?id=54765)\n",
    "\n",
    "![Dog](dog.jpg)\n",
    "![Cat](cat.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concrete Crack Detection\n",
    "\n",
    "**Goal**: Develop a model to classify concrete images as having cracks or not. The dataset is designed to facilitate the identification of structural issues in concrete buildings.\n",
    "\n",
    "**Approach**: Create a Convolutional Neural Network (CNN) to classify the images into negative (no crack) and positive (crack) categories. Experiment with various CNN architectures and techniques to determine the most effective method. Use image processing techniques to handle variations in surface finish and illumination. Ensure the model generalizes well by using cross-validation and monitoring for overfitting.\n",
    "\n",
    "**Dataset**: The dataset contains 40,000 images, with 20,000 images per class (negative and positive). Each image is 227 x 227 pixels with RGB channels. The data is collected from 458 high-resolution images (4032 x 3024 pixels) from various METU Campus Buildings. No data augmentation such as random rotation or flipping is applied.\n",
    "\n",
    "[Source](https://data.mendeley.com/datasets/5y9wdsg2zt/2)\n",
    "\n",
    "![Crack](crack_example.jpg)\n",
    "![No Crack](crack_negative.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scene Classification\n",
    "\n",
    "**Goal**: Develop a model to classify natural scene images into one of six categories. The dataset aims to facilitate the recognition of various natural scenes from around the world.\n",
    "\n",
    "**Approach**: Design a Convolutional Neural Network (CNN) to classify images into six categories: buildings, forest, glacier, mountain, sea, and street. Test different CNN architectures to find the best performing model. Apply data augmentation techniques to improve generalization. Separate the data into training, testing, and prediction sets to evaluate model performance effectively.\n",
    "\n",
    "**Dataset**: The dataset contains around 25,000 images of size 150 x 150 pixels, distributed across six categories. The data is separated into training (14,000 images), testing (3,000 images), and prediction (7,000 images) sets.\n",
    "\n",
    "[Source](https://www.kaggle.com/datasets/puneet6060/intel-image-classification?resource=download)\n",
    "\n",
    "\n",
    "![Builings](natural_scenes_buildings.jpg)\n",
    "![Forest](natural_scenes_forest.jpg)\n",
    "![Glacier](natural_scenes_glacier.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose your own dataset!\n",
    "\n",
    "Feel free to choose your own dataset.\n",
    "\n",
    "If you do so. It is best to organzie the data in image folders like this:\n",
    "\n",
    "```\n",
    "dataset/\n",
    "├── class1/\n",
    "│   ├── img1.jpg\n",
    "│   ├── img2.jpg\n",
    "│   └── ...\n",
    "├── class2/\n",
    "│   ├── img1.jpg\n",
    "│   ├── img2.jpg\n",
    "│   └── ...\n",
    "└── ...\n",
    "```\n",
    "If you don't have train/val folders this is fine. The separation can be made later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Data\n",
    "\n",
    "Specify the dataset that you want to use and download it (unless you are using your own - in that case place it in your data directory).\n",
    "\n",
    "**Download and extraction may take a few minutes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_cv_lectures.data import (\n",
    "    cats_vs_dogs,\n",
    "    concrete_cracks,\n",
    "    eurosat,\n",
    "    scene_classification,\n",
    ")\n",
    "\n",
    "cats_vs_dogs.download(DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Overall Approach\n",
    "\n",
    "\n",
    "### 1) Data Preparation & Data Inspection\n",
    "\n",
    "- Download the data\n",
    "- Inspect the data formats\n",
    "- Build a `torch.utils.data.Dataset`\n",
    "    - define training, validation and test sets\n",
    "- Implement a `torch.utils.data.DataLoader'\n",
    "- Inspect the data:\n",
    "    - Look at samples\n",
    "    - Inspect the label distribution\n",
    "\n",
    "### 2) Implement Baselines\n",
    "\n",
    "- Implement a small CNN\n",
    "- Overfitt CNN on one batch\n",
    "- Inspect pre-processing\n",
    "  \n",
    "### 3) Train a large model\n",
    "- Use a pre-trained model and train it on your task\n",
    "  \n",
    "### 4) Regularize\n",
    "- Is it beneficial to collect more data?\n",
    "- Data Augmentation\n",
    "- Early Stopping on Validation Set\n",
    "- Weight Decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1) - Data Preparation & Data Inspection\n",
    "\n",
    "- Inspect the data formats and file organization\n",
    "- Remove corrupt data\n",
    "- Build a [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)\n",
    "    - define training, validation and test sets\n",
    "- Implement a [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
    "- Inspect the data:\n",
    "    - Look at samples\n",
    "    - Inspect the label distribution\n",
    "\n",
    "\n",
    "Important information about how to define a dataset can be found here: [https://pytorch.org/docs/stable/data.htm](https://pytorch.org/docs/stable/data.htm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data Format & Organization\n",
    "\n",
    "We need to figure out how the data is organized. Particularly, how the data is labelled, to correctly define it with a [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset).\n",
    "\n",
    "First you should look at the data / folder structure of the downloaded data.\n",
    "\n",
    "(this example command only works on Linux)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find {DATA_PATH}/cats_vs_dogs/PetImages/ -type d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the data is neatly organized in class-specific folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!find {DATA_PATH}/cats_vs_dogs/PetImages/Cat/ -type f | head -n 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we have \".jpg\" files. This needs to be verified further.\n",
    "\n",
    "**Note**: You might want to check for corrupt files since they disrupt further processes. You could read each file using `PIL.Image.open` to find any errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a function to provide an inventory of all the files, along with their labels.\n",
    "\n",
    "Change the path accordingly if you used a different dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_cv_lectures.utils import find_all_imges_and_their_labels\n",
    "\n",
    "image_root_path = DATA_PATH.joinpath(\"cats_vs_dogs/PetImages\")\n",
    "\n",
    "observations = find_all_imges_and_their_labels(image_root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: How many images are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a Dataset class\n",
    "\n",
    "Once you have figured out how the data is organized we can build a [torch.utils.data.Dataset](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset). \n",
    "\n",
    "In this case we can build a map-style dataset that allows for random-access and implements `__getitem__`. We subclass `torch.utils.data.Dataset`.\n",
    "\n",
    "**Note**: Note the option to use a `transform` function that is being applied to each image. This is going to be important!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_cv_lectures.utils import find_all_imges_and_their_labels\n",
    "\n",
    "\n",
    "class ImageFolder(Dataset):\n",
    "    \"\"\"Create Dataset from class specific folders.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_path: str | Path,\n",
    "        transform: Callable | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_path: Path to directory that contains the class-specific folders\n",
    "            transform: Optional transform to be applied on an image\n",
    "            classes: List of class names.\n",
    "        \"\"\"\n",
    "        self.root_path = root_path\n",
    "        self.observations = find_all_imges_and_their_labels(root_path)\n",
    "        self.transform = transform\n",
    "        self.classes = sorted({x[\"label\"] for x in self.observations})\n",
    "        print(\n",
    "            f\"Found the following classes: {self.classes}, in total {len(self.observations)} images\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.observations)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        image_path = self.observations[idx][\"image_path\"]\n",
    "        image = Image.open(image_path)\n",
    "        label = self.observations[idx][\"label\"]\n",
    "        label_num = self.classes.index(label)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return {\"image\": image, \"label\": label_num}\n",
    "\n",
    "    @classmethod\n",
    "    def from_subset(\n",
    "        cls,\n",
    "        original_dataset,\n",
    "        subset_indices: list[int],\n",
    "        transform: Callable | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Create a subset of the original dataset with only the specified indices.\n",
    "\n",
    "        Args:\n",
    "            original_dataset (ImageFolder): An instance of the ImageFolder dataset.\n",
    "            subset_indices (List[int]): List of indices to create a subset of observations.\n",
    "            transform: Override transform of current ds\n",
    "\n",
    "        Returns:\n",
    "            ImageFolder: A new instance of ImageFolder with the subset observations.\n",
    "        \"\"\"\n",
    "        # Create a new instance with the same properties as the original\n",
    "        subset_instance = cls(\n",
    "            root_path=original_dataset.root_path,\n",
    "            transform=original_dataset.transform if transform is None else transform,\n",
    "        )\n",
    "\n",
    "        # Filter the observations based on the subset indices\n",
    "        subset_instance.observations = [original_dataset.observations[i] for i in subset_indices]\n",
    "        subset_instance.classes = original_dataset.classes  # Keep class list consistent\n",
    "\n",
    "        print(\n",
    "            f\"Created a subset with {len(subset_instance.observations)} images \"\n",
    "            f\"from the original dataset of {len(original_dataset.observations)} images\"\n",
    "        )\n",
    "\n",
    "        return subset_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What is the role of: `label_num = self.classes.index(label)`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the dataset object and inspect the first observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ImageFolder(image_root_path)\n",
    "ds.classes\n",
    "ds[0]\n",
    "ds[0][\"image\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Train / Test Splits\n",
    "\n",
    "We create train (validation) and test splits early, before we look at the data in more detail. This avoids any biases and insights that we might clean from the test set. We should set this part of the data aside and look at it only for a final model evaluation.\n",
    "\n",
    "We use a function from `sklearn.model_selection`.\n",
    "\n",
    "We balance the labels by using the `stratify` option.\n",
    "\n",
    "**Note**: Some datasets may have a pre-defined split. If so, the images might be in separate test/train folders. If that is the case simply create different dataset objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_ids = [i for i in range(0, len(ds.observations))]\n",
    "all_labels = [x[\"label\"] for x in ds.observations]\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    all_ids,\n",
    "    stratify=all_labels,\n",
    "    test_size=0.2,\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "train_ids, val_ids = train_test_split(\n",
    "    train_ids,\n",
    "    stratify=[all_labels[i] for i in train_ids],\n",
    "    test_size=0.1,\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "\n",
    "ds_train = ImageFolder.from_subset(ds, train_ids)\n",
    "ds_val = ImageFolder.from_subset(ds, val_ids)\n",
    "ds_test = ImageFolder.from_subset(ds, test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-974feaab57d71ef1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question**: Why do we need a training, validation and a testset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test the `Dataset` object by getting and visualising a sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation = ds_train[0]\n",
    "ts.show(observation[\"image\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For model training we need to batch examples. Thats why we need to define a [torch.utils.data.DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader).\n",
    "\n",
    "Let's see how our data is being batched, after all each observation is a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = DataLoader(ds_train, batch_size=16, shuffle=True)\n",
    "\n",
    "try:\n",
    "    observations = next(iter(dl_train))\n",
    "except TypeError as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oops that did not go well!**: What did we miss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_train = transforms.Compose([transforms.v2.RGB(), transforms.ToTensor()])\n",
    "\n",
    "ds_train = ImageFolder.from_subset(ds, train_ids, transform=tr_train)\n",
    "ds_val = ImageFolder.from_subset(ds, val_ids, transform=tr_train)\n",
    "ds_test = ImageFolder.from_subset(ds, test_ids, transform=tr_train)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=16, shuffle=True)\n",
    "\n",
    "try:\n",
    "    observations = next(iter(dl_train))\n",
    "except (RuntimeError, TypeError) as e:\n",
    "    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oops that did not go well!**: What did we miss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_train = transforms.Compose(\n",
    "    [transforms.v2.RGB(), transforms.Resize((64, 64)), transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "ds_train = ImageFolder.from_subset(ds, train_ids, transform=tr_train)\n",
    "ds_val = ImageFolder.from_subset(ds, val_ids, transform=tr_train)\n",
    "ds_test = ImageFolder.from_subset(ds, test_ids, transform=tr_train)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=16, shuffle=True)\n",
    "\n",
    "try:\n",
    "    observations = next(iter(dl_train))\n",
    "except (RuntimeError, TypeError) as e:\n",
    "    print(f\"Error occurred: {e}\")\n",
    "\n",
    "observations.keys()\n",
    "\n",
    "observations[\"image\"].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8385aee74294e0fc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question**: How does the DataLoader batch the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the Data\n",
    "\n",
    "Now you can use the `ImageDataset` or `DataLoader` objects to insepct the dataset. \n",
    "\n",
    "**Note**: We use only the training dataset to inspect the data.\n",
    "\n",
    "- **Initial Step**: Avoid touching neural net code initially; focus on inspecting the data thoroughly.\n",
    "- **Time Investment**: Spend hours scanning thousands of examples to understand their distribution and look for patterns.\n",
    "- **Identify Issues**: Look for duplicate examples, corrupted images/labels, data imbalances, and biases.\n",
    "- **Classify Process**: Pay attention to how you classify the data to inform the architecture exploration.\n",
    "- **Feature Analysis**: Determine if local features or global context is needed.\n",
    "- **Variation Analysis**: Assess the variation in the data, identify spurious variations for preprocessing.\n",
    "- **Spatial Consideration**: Evaluate if spatial position matters or if averaging it out is beneficial.\n",
    "- **Detail and Downsampling**: Consider the importance of detail and the feasibility of downsampling images.\n",
    "- **Label Noise**: Assess the noise level in the labels.\n",
    "- **Understand Predictions**: Use network (mis)predictions to understand inconsistencies and data issues (at a later stage!).\n",
    "- **Quantitative Analysis**: Write simple code to search, filter, and sort data by various attributes.\n",
    "- **Visualize Distributions**: Visualize distributions and outliers to uncover bugs in data quality or preprocessing.\n",
    "\n",
    "For now do at least the following:\n",
    "- what is the class distribution?\n",
    "- how difficult do you think is the problem?\n",
    "- are there any obvious issues with the data?\n",
    "- do the labels seem accurate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-556797ba20290ab9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.unique([obs[\"label\"] for obs in ds_train.observations], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Use functions to visualize and inspect the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Implement Baselines\n",
    "\n",
    "In this step we want to implement a training pipeline and evaluate simple baselines to get a feeling for the problem and to test and verify if the pipeline works.\n",
    "\n",
    "**Reproducibility**\n",
    "\n",
    "- Fix random seed: Always use a fixed random seed to ensure consistent outcomes in repeated runs.\n",
    "\n",
    "**Simplification and Initialization**\n",
    "\n",
    "- Simplify: Disable unnecessary features like data augmentation initially.\n",
    "- Verify loss at initialization: Ensure loss starts at the expected value.\n",
    "\n",
    "**Baselines and Metrics**\n",
    "\n",
    "- Human baseline: Compare model metrics to human-interpretable metrics (e.g., accuracy).\n",
    "- Input-independent baseline: Train a baseline model with zeroed inputs and compare it to a variant with normal data. There should be a clear difference!\n",
    "\n",
    "**Overfitting and Visualization**\n",
    "\n",
    "- Overfit one batch: Overfit a single batch to verify the model can reach the minimum loss.\n",
    "- Verify decreasing training loss: Ensure training loss decreases when model capacity increases.\n",
    "- Visualize before the net: Visualize data immediately before feeding it to the network to catch preprocessing issues.\n",
    "- Visualize prediction dynamics: Track model predictions on a fixed test batch during training to understand training progression.\n",
    "\n",
    "**Evaluation**\n",
    "\n",
    "- Add significant digits to your eval: Evaluate on the entire test set for accuracy.\n",
    "- Visualize: Visualize model inputs and outputs to ensure correctness.\n",
    "\n",
    "**Additional Tips**\n",
    "\n",
    "- Verify simplifications: Simplify initial setup by turning off data augmentation and complex features to reduce bugs.\n",
    "\n",
    "We will address some of the steps above. Feel free to do more!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility\n",
    "\n",
    "The `lightning`package provides a function to set random seeds of different modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "L.seed_everything(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple DataLoader\n",
    "\n",
    "Implement a simple dataloader without fancy transformations. To specify transformations, use [torchvision.transforms](https://pytorch.org/vision/0.9/transforms.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple transformation\n",
    "tr_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.v2.RGB(),\n",
    "        transforms.Resize((32, 32)),\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds_train = ImageFolder.from_subset(ds, train_ids, transform=tr_train)\n",
    "dl_train = DataLoader(ds_train, batch_size=16, shuffle=True, num_workers=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = next(iter(dl_train))\n",
    "ts.show(obs[\"image\"])\n",
    "obs[\"image\"].max()\n",
    "obs[\"image\"].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Model\n",
    "\n",
    "Start with a simple model that is (most likely) correct and should be able to learn something (quickly).\n",
    "\n",
    "Implement the following architecture:\n",
    "\n",
    "- Convolution: 16 Filters, Kernel-Size 5x5\n",
    "- Pooling: Stride 2, Kernel-Size 2\n",
    "- Convolution: 32 Filter, Kernel-Size 5x5\n",
    "- Global Average Pooling\n",
    "- FC: 2 with **number of classes** neurons\n",
    "\n",
    "Use `ReLU` activation after each convolution.\n",
    "\n",
    "Define a class which inherits from `torch.nn.Module`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-282219b1ddf201ab",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, (5, 5))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 5)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(32, 2)  # adapt to the number of classes here\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = SmallCNN()\n",
    "\n",
    "print(net)\n",
    "print(torchinfo.summary(net, input_size=(1, 3, 32, 32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-62ef301fb1d10cf0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question**: Briefly explain what happens with a data point during the forward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a training Loop\n",
    "\n",
    "We use Lightning which greatly simplifys implementing boilerplate code such as  training loops.\n",
    "\n",
    "Tutorial here: https://lightning.ai/pages/community/tutorial/step-by-step-walk-through-of-pytorch-lightning/\n",
    "\n",
    "We also include additional metrics from [torchmetrics](https://lightning.ai/docs/torchmetrics/stable/) to easily log and calculate accuracy.  Adapt `task=\"binary\"` if necessary!\n",
    "\n",
    "**Note**: Calculating the metrics incorrectly is a common source of errors. Make sure to correctly aggregate metrics across an epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchmetrics\n",
    "\n",
    "\n",
    "class Classifier(L.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.train_accuracy = torchmetrics.Accuracy(\n",
    "            task=\"binary\"\n",
    "        )  # Adjust task if you have more than two classes\n",
    "        self.train_loss = torchmetrics.MeanMetric()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch[\"image\"], batch[\"label\"]\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Update accuracy metric\n",
    "        self.train_accuracy(preds, y)\n",
    "        self.train_loss(loss)\n",
    "\n",
    "        self.log(\"train/acc_step\", self.train_accuracy, prog_bar=True)\n",
    "        self.log(\"train/loss_step\", self.train_loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # log epoch metric\n",
    "        self.log(\"train/acc_epoch\", self.train_accuracy)\n",
    "        self.log(\"train/loss_epoch\", self.train_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the following parameters accoring to your hardware if you need. As you can see, this simplifies hardware switches greatly!\n",
    "\n",
    "We want to perform a functional check only. Train the model only for 10 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(123)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    precision=\"32\",\n",
    "    max_steps=10,\n",
    "    enable_checkpointing=False,\n",
    "    logger=False,\n",
    "    default_root_dir=DATA_PATH.joinpath(\"lightning_logs\"),\n",
    ")\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=128, shuffle=True, num_workers=5)\n",
    "\n",
    "net = SmallCNN()\n",
    "model = Classifier(net)\n",
    "trainer.fit(model, train_dataloaders=dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What is the loss at initialization / after 10 steps? Does the value make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train the model for longer to get a sense of the performance (increase the number of steps `max_steps` the model is training for)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(123)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    precision=\"32\",\n",
    "    max_steps=10,\n",
    "    enable_checkpointing=False,\n",
    "    logger=False,\n",
    "    default_root_dir=DATA_PATH.joinpath(\"lightning_logs\"),\n",
    ")\n",
    "\n",
    "net = SmallCNN()\n",
    "model = Classifier(net)\n",
    "trainer.fit(model, train_dataloaders=dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.logged_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What is your conclusion? Does learning take place?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfit on one Batch of Data\n",
    "\n",
    "We train the model with only one batch. This means the model only ever sees the same `batch_size` number of images.\n",
    "\n",
    "You might want to increase `max_steps`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-76e81732d77174f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question**: What do you expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(123)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    precision=\"32\",\n",
    "    max_steps=10,\n",
    "    enable_checkpointing=False,\n",
    "    logger=False,\n",
    "    default_root_dir=DATA_PATH.joinpath(\"lightning_logs\"),\n",
    "    # this option limits the training set to one batch, disables shuffle\n",
    "    overfit_batches=1,\n",
    ")\n",
    "\n",
    "net = SmallCNN()\n",
    "model = Classifier(net)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=16, shuffle=True, num_workers=5)\n",
    "trainer.fit(model, train_dataloaders=dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Metrics:  {trainer.logged_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Did it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Train a large model\n",
    "\n",
    "In this step we try to drive the trainings-loss as low as possible.\n",
    "\n",
    "**Model Selection and Initialization**\n",
    "\n",
    "- Pick a proven model: Start with a simple, well-established architecture (e.g., ResNet-50 for image classification) rather than creating complex, custom models.\n",
    "- Use Adam optimizer: Begin with Adam and a learning rate of 3e-4 for its forgiving nature with hyperparameters (or the PyTorch default value).\n",
    "\n",
    "**Gradual Complexity**\n",
    "\n",
    "- Add complexity incrementally: Integrate multiple signals or features into your classifier one at a time, ensuring each addition improves performance.\n",
    "\n",
    "\n",
    "You can do the following:\n",
    "- implement your own model\n",
    "- use a pre-defined model\n",
    "- use a pre-defined AND pre-trained model\n",
    "\n",
    "**Important**: Inspect how the model performs. Which samples does it correctly classify? Which samples are wrong? Do you see a pattern? Can this be fixes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "We load the data again and start from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_cv_lectures import utils\n",
    "from dl_cv_lectures.data.image_folder import ImageFolder\n",
    "\n",
    "image_root_path = DATA_PATH.joinpath(\"cats_vs_dogs/PetImages\")\n",
    "\n",
    "ds = ImageFolder(image_root_path)\n",
    "\n",
    "all_ids = [i for i in range(0, len(ds.observations))]\n",
    "all_labels = [x[\"label\"] for x in ds.observations]\n",
    "\n",
    "train_ids, val_ids, test_ids = utils.create_train_test_split(\n",
    "    all_ids, all_labels, random_state=123, test_size=0.2, val_size=0.1\n",
    ")\n",
    "\n",
    "\n",
    "ds_train = ImageFolder.from_subset(ds, train_ids)\n",
    "ds_val = ImageFolder.from_subset(ds, val_ids)\n",
    "ds_test = ImageFolder.from_subset(ds, test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1f3c0de79c9f603b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## Pre-Trained Model\n",
    "\n",
    "In the following we will use a pre-trained model and adapt it to our dataset (transfer-learning).\n",
    "\n",
    "### Load Model\n",
    "\n",
    "Here we use a pre-trained model.  Read the doc here: [https://pytorch.org/vision/0.8/models.html](https://pytorch.org/vision/0.8/models.html).)\n",
    "\n",
    "**It is important to read how the data is pre-processed for a given pre-trained model. This should be consistent with how you pre-process the data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-39c22ca50688c3fe",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "net = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "\n",
    "tr_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.v2.RGB(),\n",
    "        transforms.RandomResizedCrop((128, 128)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tr_val = transforms.Compose(\n",
    "    [\n",
    "        transforms.v2.RGB(),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "print(torchinfo.summary(net, input_size=(1, 3, 64, 64)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we adapt the output layer to match our dataset.\n",
    "\n",
    "**Adapt** to the correct number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.fc = nn.Sequential(nn.Linear(512, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train the model. \n",
    "\n",
    "We also use a `logger` object to log the training process.\n",
    "\n",
    "Again: Adjust the parameters of the trainer class to your liking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_cv_lectures.data.image_folder import DataSetModule\n",
    "\n",
    "L.seed_everything(123)\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "logger = TensorBoardLogger(DATA_PATH.joinpath(\"lightning_logs\"), name=\"overfit_baseline1\")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    precision=\"32\",\n",
    "    max_steps=10,\n",
    "    enable_checkpointing=False,\n",
    "    logger=logger if not DEBUG else None,\n",
    "    default_root_dir=DATA_PATH.joinpath(\"lightning_logs\"),\n",
    ")\n",
    "\n",
    "model = Classifier(net)\n",
    "\n",
    "\n",
    "dm = DataSetModule(\n",
    "    ds_train=ds_train,\n",
    "    ds_val=ds_val,\n",
    "    ds_test=ds_test,\n",
    "    classes=[\"Cat\", \"Dog\"],\n",
    "    train_transform=tr_train,\n",
    "    test_transform=tr_val,\n",
    "    batch_size=64,\n",
    ")\n",
    "\n",
    "\n",
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Metrics:  {trainer.logged_metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the tensorboard logs. This may not work in a container without opening tensorboard ports.\n",
    "\n",
    "(You would need to add the following options to docker run `-p 6006-6015:6006-6015`)\n",
    "\n",
    "If working locally, you can simply type: `localhost:6008' in your browser, after executing he following lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir={DATA_PATH.joinpath(\"lightning_logs\")} --host 0.0.0.0 --port=6007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Feel Free to try a larger model and observe the performance. You also might want to train your model longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: It is important to insepct model performance at this point. Try to figure out where the model works well and where it fails. And try to figure out why and if you can do something about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4) - Regularization\n",
    "\n",
    "Regularization is a process to deliberately limit a model's capacity in order to reduce overfitting and to improve generalization.\n",
    "\n",
    "**Data Collection and Augmentation**\n",
    "\n",
    "- Get more data: Collect additional real training data for the most effective regularization.\n",
    "- Data augmentation: Use more aggressive data augmentation techniques.\n",
    "- Creative augmentation: Explore simulation, hybrid methods, or GANs to expand datasets.\n",
    "\n",
    "**Model Initialization and Size**\n",
    "\n",
    "- Pretrain: Utilize pretrained networks when possible.\n",
    "- Smaller input dimensionality: Remove features with spurious signals and reduce image size if low-level details are not critical.\n",
    "- Smaller model size: Use domain knowledge to constrain and reduce the size of the network.\n",
    "\n",
    "**Regularization Techniques**\n",
    "\n",
    "- Decrease batch size: Smaller batch sizes can act as stronger regularizers due to batch normalization effects.\n",
    "- Add dropout: Use dropout (including dropout2d for ConvNets) sparingly.\n",
    "- Weight decay: Increase the weight decay penalty.\n",
    "- Early stopping: Stop training based on validation loss to avoid overfitting.\n",
    "\n",
    "**Model Complexity**\n",
    "\n",
    "- Try a larger model: Consider larger models for potentially better early-stopped performance, despite higher risk of eventual overfitting.\n",
    "\n",
    "  \n",
    "\n",
    "You can try the following techniques:\n",
    "\n",
    "- Weight Decay\n",
    "- Data Augmentation\n",
    "- Early Stopping on Validation Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Decay\n",
    "\n",
    "Weight decay is a technique to reduce model complexity by adding a penalty to the magnitude of the weights. It can be implemented by decaying the weights towards 0 after each gradient descent step. \n",
    "\n",
    "Read the following documentation and add Weight Decay to your model: [torch.optim.Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam)\n",
    "\n",
    "It is implemented in the optimizer.\n",
    "\n",
    "Make it configurable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1df2c55234f1bd22",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class Classifier(L.LightningModule):\n",
    "    def __init__(self, model, weight_decay: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.weight_decay = weight_decay\n",
    "        self.train_accuracy = torchmetrics.Accuracy(task=\"binary\")\n",
    "        self.train_loss = torchmetrics.MeanMetric()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch[\"image\"], batch[\"label\"]\n",
    "        logits = self(x)\n",
    "        loss = self.loss_fn(logits, y)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "        # Update accuracy metric\n",
    "        self.train_accuracy(preds, y)\n",
    "        self.train_loss(loss)\n",
    "\n",
    "        self.log(\"train_acc_step\", self.train_accuracy, prog_bar=True)\n",
    "        self.log(\"train_loss_step\", self.train_loss, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # log epoch metric\n",
    "        self.log(\"train_acc_epoch\", self.train_accuracy)\n",
    "        self.log(\"train_loss_epoch\", self.train_loss)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=0.001, weight_decay=self.weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "Data augmentation is the process of applying random transformations to the input data before it is processed by the model. This increases the robustness of the model and improves its generalization capabilities.\n",
    "\n",
    "**Note**: Always check if the data augmentations are plausible and not too extreme!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_train = transforms.Compose(\n",
    "    [\n",
    "        transforms.v2.RGB(),\n",
    "        transforms.RandomResizedCrop((128, 128)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tr_val = transforms.Compose(\n",
    "    [\n",
    "        transforms.v2.RGB(),\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ds_train = ImageFolder.from_subset(ds, train_ids, transform=tr_train)\n",
    "\n",
    "dl_train = DataLoader(ds_train, batch_size=16, shuffle=True, num_workers=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = next(iter(dl_train))\n",
    "\n",
    "ts.show(obs[\"image\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Does the data still look plausible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(123)\n",
    "\n",
    "logger = TensorBoardLogger(DATA_PATH.joinpath(\"lightning_logs\"), name=\"data_augmentation\")\n",
    "\n",
    "DEBUG = True\n",
    "\n",
    "model = Classifier(net)\n",
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    precision=\"32\",\n",
    "    max_steps=10,\n",
    "    enable_checkpointing=False,\n",
    "    logger=logger if not DEBUG else None,\n",
    "    default_root_dir=DATA_PATH.joinpath(\"lightning_logs\"),\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=dl_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping\n",
    "\n",
    "Early stopping monitors the training process on a separate validation set to determine the optimal point regarding when to stop training (when validation loss / metric is at the best level).\n",
    "\n",
    "Pytorch-lightning provides such functionality out-of-the-box: [pytorch_lightning.callbacks.early_stopping.EarlyStopping](https://lightning.ai/docs/pytorch/stable/common/early_stopping.html)\n",
    "\n",
    "**Make sure to let the model run enough steps such that early stopping is actually stopping the training!**\n",
    "\n",
    "Implement a metric which early stopping should monitor. It should be one calculated on the validation set.\n",
    "\n",
    "\n",
    "Inspect the `Trainer` class and set more appropriate values  (e.g. `val_check_interval` and `max_steps`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-1f63d38b919c30a9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from lightning.pytorch.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val/accuracy_epoch\", min_delta=0.00, patience=3, mode=\"max\", verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a more fully fledged class of a classifier lightning module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.seed_everything(123)\n",
    "\n",
    "from dl_cv_lectures import classifier\n",
    "\n",
    "logger = TensorBoardLogger(DATA_PATH.joinpath(\"lightning_logs\"), name=\"early_stopping\")\n",
    "\n",
    "DEBUG = True\n",
    "model = classifier.Classifier(net, num_classes=2)\n",
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    precision=\"32\",\n",
    "    max_steps=10,\n",
    "    enable_checkpointing=False,\n",
    "    logger=logger if not DEBUG else None,\n",
    "    callbacks=[early_stopping],  # Add the early stopping callback here\n",
    "    default_root_dir=DATA_PATH.joinpath(\"lightning_logs\"),\n",
    ")\n",
    "\n",
    "dl_val = DataLoader(ds_val, batch_size=64, shuffle=False, num_workers=5)\n",
    "\n",
    "trainer.fit(model, train_dataloaders=dl_train, val_dataloaders=dl_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Compare training metrics with validation metrics. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-52424cc5813975bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "## 3) Evaluate your model\n",
    "\n",
    "We may want to evaluate our model in more detail. In particular we want to know where the model works well and where it fails. This might give us additional insight in the data and the difficulties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_cv_lectures import utils\n",
    "from dl_cv_lectures.data.image_folder import ImageFolder\n",
    "\n",
    "image_root_path = DATA_PATH.joinpath(\"cats_vs_dogs/PetImages\")\n",
    "\n",
    "ds = ImageFolder(image_root_path)\n",
    "\n",
    "all_ids = [i for i in range(0, len(ds.observations))]\n",
    "all_labels = [x[\"label\"] for x in ds.observations]\n",
    "\n",
    "train_ids, val_ids, test_ids = utils.create_train_test_split(\n",
    "    all_ids, all_labels, random_state=123, test_size=0.2, val_size=0.1\n",
    ")\n",
    "\n",
    "ds_train = ImageFolder.from_subset(ds, train_ids)\n",
    "ds_val = ImageFolder.from_subset(ds, val_ids)\n",
    "ds_test = ImageFolder.from_subset(ds, test_ids)\n",
    "\n",
    "\n",
    "dm = DataSetModule(\n",
    "    ds_train=ds_train,\n",
    "    ds_val=ds_val,\n",
    "    ds_test=ds_test,\n",
    "    classes=[\"Cat\", \"Dog\"],\n",
    "    train_transform=tr_train,\n",
    "    test_transform=tr_val,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    devices=\"auto\",\n",
    "    accelerator=\"auto\",\n",
    "    precision=\"32\",\n",
    "    max_epochs=2,\n",
    "    enable_checkpointing=False,\n",
    "    default_root_dir=DATA_PATH.joinpath(\"lightning_logs\"),\n",
    ")\n",
    "\n",
    "# trainer.test(model, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3368f29ef9e4cc98",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Confusion-Matrix\n",
    "\n",
    "Plotten Sie eine _confusion matrix_. Benutzen Sie \n",
    "\n",
    "- [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "- [ConfusionMatrixDisplay](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.ConfusionMatrixDisplay.html#sklearn.metrics.ConfusionMatrixDisplay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-78b9e4f3c69747d5",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# cm = confusion_matrix(y_true=true_all, y_pred=predicted_all)\n",
    "# disp = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
    "# disp.plot(ax=ax, xticks_rotation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which classes are confused how?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
