{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "header",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "try:\n",
    "    import jupyter_black\n",
    "\n",
    "    jupyter_black.load()\n",
    "except:\n",
    "    print(\"black not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "title",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Convolutional Neural Networks\n",
    "\n",
    "## Goals\n",
    "\n",
    "- Convolutions: Apply on images\n",
    "- CNNs: Define, Optimize, Inspect, Understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a9856bbf98ea570f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Setup\n",
    "\n",
    "Let's define paths, install & load the necessary Python packages.\n",
    "\n",
    "**Optional: Save the notebook to your personal google drive to persist changes.**\n",
    "\n",
    "**Optional: Change runtime to a GPU instance (if using Google Colab)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mount your google drive to store data and results (if running the code in Google Colab)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "print(f\"In colab: {IN_COLAB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modify the following paths if necessary.**\n",
    "\n",
    "That is where your data will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "if IN_COLAB:\n",
    "    DATA_PATH = Path(\"/content/drive/MyDrive/bveri\")\n",
    "else:\n",
    "    DATA_PATH = Path(\"/workspace/code/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the package `dl_cv_lectures`.\n",
    "\n",
    "The following code installs the package from a local repository (if available), otherwise it installs it from the exercise repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import dl_cv_lectures\n",
    "\n",
    "    print(\"dl_cv_lectures installed, all good\")\n",
    "except ImportError as e:\n",
    "    import os\n",
    "\n",
    "    if Path(\"/workspace/code/src\").exists():\n",
    "        print(\"Installing from local repo\")\n",
    "        os.system(\"cd /workspace/code  && pip install .\")\n",
    "    else:\n",
    "        print(\"Installing from git repo\")\n",
    "        os.system(\"pip install git+https://github.com/i4Ds/bveri-exercises-hs2024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import math\n",
    "import random\n",
    "from typing import Callable\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "import torchshow as ts\n",
    "import torchvision\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.v2 import functional as TF\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a default device for your computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Convolutions in PyTorch\n",
    "\n",
    "We apply a _convolution_ on images.\n",
    "\n",
    "Let's get an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://github.com/pytorch/vision/blob/main/gallery/assets/dog2.jpg?raw=true\"\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "image = Image.open(io.BytesIO(r.content))\n",
    "\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform *convolutions*. There are two approaches for this:\n",
    "\n",
    "- *Functional* approach, using functions that are *stateless* [nn.functional](https://pytorch.org/docs/stable/nn.functional.html)\n",
    "- Using modules (objects), which have a *state* and are used in neural networks [torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "# convert PIL.Image to torch.tensor (takes care of channel format -> CHW)\n",
    "input = TF.pil_to_tensor(image).float() / 255.0\n",
    "\n",
    "# define filter by hand\n",
    "filter = filter = (\n",
    "    torch.tensor(\n",
    "        [\n",
    "            [[1, 0, -1], [1, 0, -1], [1, 0, -1]],  # R\n",
    "            [[1, 0, -1], [1, 0, -1], [1, 0, -1]],  # G\n",
    "            [[1, 0, -1], [1, 0, -1], [1, 0, -1]],  # B\n",
    "        ]\n",
    "    )\n",
    "    .unsqueeze(0)\n",
    "    .float()\n",
    ")\n",
    "\n",
    "ts.show(filter, show_axis=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional approach\n",
    "result = F.conv2d(input, filter, stride=1, padding=0, dilation=1, groups=1)\n",
    "\n",
    "# rescale result to visualize it as an image\n",
    "result_scaled = (result - result.min()) / (result.max() - result.min())\n",
    "\n",
    "ts.show(result_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we perform a *convolution* using a *module*. [torch.nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# module\n",
    "conv = torch.nn.Conv2d(\n",
    "    in_channels=3,\n",
    "    out_channels=1,\n",
    "    kernel_size=3,\n",
    "    stride=1,\n",
    "    padding=0,\n",
    "    dilation=1,\n",
    "    groups=1,\n",
    ")\n",
    "\n",
    "result = conv(input)\n",
    "\n",
    "# rescale result to visualize it as an image\n",
    "result_scaled = (result - result.min()) / (result.max() - result.min())\n",
    "\n",
    "\n",
    "ts.show(result_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dfdbcda98b2ef9b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question**: What is the difference between the *functional* and *module* approach? What happens in the *module* approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f5c47ead81e89eb2",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now apply the following operations to the image using the *functional* approach:\n",
    "\n",
    "- Convolution\n",
    "- Max Pooling\n",
    "- Convolution\n",
    "\n",
    "You can use the filter from above, if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f6d5d5c659007899",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x = F.conv2d(input, filter, stride=1, padding=0, dilation=1, groups=1)\n",
    "x = F.max_pool2d(x, kernel_size=(2, 2), stride=(2, 2))\n",
    "result = F.conv2d(x, filter[:, 0:1, :, :], stride=1, padding=0, dilation=1, groups=1)\n",
    "\n",
    "# rescale result to visualize it as an image\n",
    "result_scaled = (result - result.min()) / (result.max() - result.min())\n",
    "ts.show(result_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) CNN Properties\n",
    "\n",
    "In the following we will conduct a few experiments to understand how CNNs work and to contrast them with MLPs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "We create a modified MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "from dl_cv_lectures.transform import RandomQuadrantPad\n",
    "\n",
    "# Create the MNIST dataset with the custom transform\n",
    "ds_mnist_train = torchvision.datasets.MNIST(\n",
    "    root=DATA_PATH,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=RandomQuadrantPad(choices=[\"top_left\"]),\n",
    ")\n",
    "\n",
    "# Create the MNIST dataset with the custom transform\n",
    "ds_mnist_test_tl = torchvision.datasets.MNIST(\n",
    "    root=DATA_PATH,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=RandomQuadrantPad(choices=[\"top_left\"]),\n",
    ")\n",
    "\n",
    "# Create the MNIST dataset with the custom transform\n",
    "ds_mnist_test_br = torchvision.datasets.MNIST(\n",
    "    root=DATA_PATH,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=RandomQuadrantPad(choices=[\"bottom_right\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize a few data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_mnist_train = torch.utils.data.DataLoader(\n",
    "    ds_mnist_train, batch_size=12, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "# Let's check the first batch\n",
    "images, labels = next(iter(dl_mnist_train))\n",
    "import torchshow\n",
    "\n",
    "ts.show(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-093dfa37667fda26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question**: What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0e0e186c30b81d8a",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture Definition\n",
    "\n",
    "We define a CNN with the following architecture:\n",
    "\n",
    "- Input Shape: (1, 28 *  2, 28 *2)\n",
    "- Convolution: 8 Filters, Kernel-Size 5x5\n",
    "- Max Pooling: Stride 2, Kernel-Size 2\n",
    "- Convolution: 16 Filter, Kernel-Size 5x5\n",
    "- Max Pooling: Stride 2, Kernel-Size 2\n",
    "- FC: 32 neurons\n",
    "- FC: 16 neurons\n",
    "- FC: 10 neurons (because we have 10 classes)\n",
    "\n",
    "We use ReLU after each layer and subclass `torch.nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6c456bb869bd831b",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchinfo\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_channel=8):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.conv1 = nn.Conv2d(1, num_channel, (5, 5))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(num_channel, num_channel * 2, 5)\n",
    "        self.fc1 = nn.Linear(num_channel * 2 * 11 * 11, num_channel * 4)\n",
    "        self.fc2 = nn.Linear(num_channel * 4, num_channel * 2)\n",
    "        self.fc3 = nn.Linear(num_channel * 2, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Layer with Conv -> ReLU -> Pool\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "print(net)\n",
    "print(torchinfo.summary(net, input_size=(1, 1, 56, 56)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Explain why this layer is defined how it is `nn.Linear(num_channel*2 * 11 * 11, num_channel*4)`.\n",
    "\n",
    "**Question**: Examine the number of parameters per layer. What do you notice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-26e0c1522d99aab7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Training\n",
    "\n",
    "We define loss function and optimizer. Since we are modelling a classification problem we use the _cross-entropy loss_. The Adam-Optimizer is a good default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-aa418fcc5649d483",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-39475ff98a1f8585",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Let's define the training-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    net: torch.nn.Module,\n",
    "    optimizer: torch.optim.Adam,\n",
    "    loss_fn: Callable,\n",
    "    device: str = \"cpu\",\n",
    "    verbose: bool = True,\n",
    "):\n",
    "\n",
    "    net = net.to(device)\n",
    "\n",
    "    with tqdm(data_loader, unit=\"batch\", disable=not verbose) as tepoch:\n",
    "\n",
    "        total_samples_seen = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        for step, (X, y) in enumerate(tepoch):\n",
    "\n",
    "            # Update Step\n",
    "            logits = net(X.to(device))\n",
    "            loss = loss_fn(logits, y.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate Accuracy\n",
    "            class_probabilities = torch.softmax(logits, axis=-1).detach().cpu()\n",
    "            y_hat = class_probabilities.argmax(dim=1, keepdim=True).squeeze().detach().cpu()\n",
    "\n",
    "            num_correct = (y_hat == y).sum().item()\n",
    "            num_samples = X.shape[0]\n",
    "            batch_accuracy = num_correct / num_samples\n",
    "\n",
    "            # Epoch Statistics\n",
    "            total_samples_seen += num_samples\n",
    "            total_correct += num_correct\n",
    "            epoch_accuracy = total_correct / total_samples_seen\n",
    "\n",
    "            if verbose:\n",
    "                tepoch.set_postfix(\n",
    "                    loss=loss.item(),\n",
    "                    accuracy_batch=batch_accuracy,\n",
    "                    accuracy_epoch=epoch_accuracy,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_mnist_train = torch.utils.data.DataLoader(\n",
    "    ds_mnist_train, batch_size=256, shuffle=True, num_workers=4\n",
    ")\n",
    "\n",
    "total_epochs = 5\n",
    "for epoch in range(0, total_epochs):\n",
    "    print(f\"Starting Epoch: {epoch + 1} / {total_epochs}\")\n",
    "    train_one_epoch(dl_mnist_train, net, optimizer, loss_fn, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate our model on test data. Lets define the test dataset and look at a few samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_mnist_test_tl = torch.utils.data.DataLoader(ds_mnist_test_tl, batch_size=32, shuffle=False)\n",
    "\n",
    "images, labels = next(iter(dl_mnist_test_tl))\n",
    "\n",
    "ts.show(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Do you think the model will perform well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_loop(\n",
    "    data_loader: torch.utils.data.DataLoader,\n",
    "    net: torch.nn.Module,\n",
    "    loss_fn: Callable,\n",
    "    device: str = \"cpu\",\n",
    ") -> tuple[float, torch.Tensor, torch.Tensor]:\n",
    "\n",
    "    net = net.to(device)\n",
    "    net.eval()\n",
    "    with tqdm(data_loader, unit=\"batch\") as tepoch:\n",
    "\n",
    "        total_samples_seen = 0\n",
    "        total_correct = 0\n",
    "\n",
    "        y_list = list()\n",
    "        y_hat_list = list()\n",
    "\n",
    "        for step, (X, y) in enumerate(tepoch):\n",
    "\n",
    "            # Forward Pass\n",
    "            with torch.no_grad():\n",
    "                logits = net(X.to(device))\n",
    "            loss = loss_fn(logits, y.to(device))\n",
    "\n",
    "            # Predictions\n",
    "            class_probabilities = torch.softmax(logits, axis=-1).detach().cpu()\n",
    "            y_hat = class_probabilities.argmax(dim=1, keepdim=True).squeeze().detach().cpu()\n",
    "\n",
    "            # Metrics\n",
    "            num_correct = (y_hat == y).sum().item()\n",
    "            num_samples = X.shape[0]\n",
    "            total_samples_seen += num_samples\n",
    "            total_correct += num_correct\n",
    "            epoch_accuracy = total_correct / total_samples_seen\n",
    "\n",
    "            tepoch.set_postfix(\n",
    "                loss=loss.item(),\n",
    "                accuracy_epoch=epoch_accuracy,\n",
    "            )\n",
    "\n",
    "            # save preds and targets\n",
    "            y_list.append(y.cpu())\n",
    "            y_hat_list.append(y_hat.cpu())\n",
    "\n",
    "    return epoch_accuracy, torch.concat(y_list), torch.concat(y_hat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, y, y_hat = eval_loop(dl_mnist_test_tl, net, loss_fn, device=device)\n",
    "\n",
    "print(f\"Test Accuracy:  {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the following test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_mnist_test_br = torch.utils.data.DataLoader(ds_mnist_test_br, batch_size=32, shuffle=False)\n",
    "\n",
    "images, labels = next(iter(dl_mnist_test_br))\n",
    "\n",
    "ts.show(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f7485417fbb9276a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Question**: How good is the model in this case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate your hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy, y, y_hat = eval_loop(dl_mnist_test_br, net, loss_fn, device=device)\n",
    "\n",
    "print(f\"Test Accuracy:  {test_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Try to improve the model by making architectural changes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
